{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all libraries \n",
    "\n",
    "import numpy as np\n",
    "from ge.classify import read_node_label,Classifier\n",
    "from ge import Node2Vec\n",
    "from ge import DeepWalk\n",
    "from ge import Exp\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from sklearn.manifold import TSNE\n",
    "import random\n",
    "import warnings\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import community as comm\n",
    "from math import floor\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_classification(embeddings, label):\n",
    "    X, Y = read_node_label(label,skip_head=True)\n",
    "    \n",
    "    ltrainfrac = [0.05, 0.1, 0.2, 0.3, .4, .5, .6, .7, .8]\n",
    "    for tf in ltrainfrac:\n",
    "        if (tf == 0.2 or tf == 0.4):\n",
    "            print(\"Training classifier using {:.2f}% nodes...\".format(tf * 100))\n",
    "        clf = Classifier(embeddings=embeddings, clf=LogisticRegression())\n",
    "        clf.split_train_evaluate(X, Y, tf)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "def makeLinkPredictionData(graph, embeddings):\n",
    "    # converting embedding to a numpy array\n",
    "    X = [[0] for i in range(G.number_of_nodes())]\n",
    "    for i in range(0, G.number_of_nodes()):\n",
    "        X[i] = embeddings[str(i+1)]\n",
    "    X = np.array(X)\n",
    "    \n",
    "    Xd = []\n",
    "    Yd = []\n",
    "    count = 0\n",
    "    for u in range(graph.number_of_nodes()):\n",
    "        Nu = list(graph.neighbors(u))\n",
    "        count += len(Nu)\n",
    "        cn = 0\n",
    "        totalns = 0\n",
    "        for n in Nu:\n",
    "            x = []\n",
    "            if n > u:\n",
    "                for d in range(len(X[0])):\n",
    "                    x.append(X[u][d] - X[n][d])\n",
    "                Xd.append(x)\n",
    "                Yd.append(1)\n",
    "                totalns += 1\n",
    "        tmpnn = []\n",
    "        if len(Nu) > graph.number_of_nodes() // 2:\n",
    "            totalns = (graph.number_of_nodes() - len(Nu)) // 2\n",
    "            print(\"Testing neighbors!\")\n",
    "        while cn < totalns:\n",
    "            nn = random.randint(0, graph.number_of_nodes() - 1)\n",
    "            if nn not in Nu and nn not in tmpnn:\n",
    "                cn += 1\n",
    "                x = []\n",
    "                for d in range(len(X[0])):\n",
    "                    x.append(X[u][d] - X[nn][d])\n",
    "                Xd.append(x)\n",
    "                Yd.append(0)\n",
    "                tmpnn.append(nn)\n",
    "    Xd, Yd = np.array(Xd), np.array(Yd)\n",
    "    indices = np.array(range(len(Yd)))\n",
    "    np.random.shuffle(indices)\n",
    "    Xt = Xd[indices]\n",
    "    Yt = Yd[indices]\n",
    "    #print(len(Xd), len(Yd), count)\n",
    "    \n",
    "    \n",
    "    ltrainfrac = [0.05, 0.1, 0.2, 0.3, .4, .5, .6, .7, .8]\n",
    "    for tf in ltrainfrac:\n",
    "        CV = int(len(Yt) * tf)\n",
    "        trainX = Xt[0:CV]\n",
    "        testX = Xt[CV:]\n",
    "        trainY = Yt[0:CV]\n",
    "        testY = Yt[CV:]\n",
    "        modelLR = LogisticRegression().fit(trainX, trainY)\n",
    "        predictedY = modelLR.predict(testX)\n",
    "        acc = accuracy_score(predictedY, testY)\n",
    "        f1macro = f1_score(predictedY, testY, average='macro', labels=np.unique(predictedY))\n",
    "        f1micro = f1_score(predictedY, testY, average='micro', labels=np.unique(predictedY))\n",
    "        print(\"Link predictions:\", tf, \":Accuracy:\",acc, \"F1-macro:\", f1macro, \"F1-micro:\",f1micro)\n",
    "\n",
    "\n",
    "def cluster_eval(G, embeddings):\n",
    "    # converting embedding to a numpy array\n",
    "    X = [[0] for i in range(G.number_of_nodes())]\n",
    "    #print(len(embeddings))\n",
    "    #length = G.number_of_nodes() - 1\n",
    "    #print(G.number_of_nodes())\n",
    "    for i in range(0, G.number_of_nodes()):\n",
    "        #print(G.number_of_nodes())\n",
    "        X[i] = embeddings[str(i+1)]\n",
    "    X = np.array(X)\n",
    "\n",
    "    bestModularity = 0\n",
    "    bestC = 2\n",
    "    NOC = 30\n",
    "    allmodularity = []\n",
    "    for cls in range(2, NOC):\n",
    "        \n",
    "        # find clusters using a kmeans clustering algorithm on the embedding\n",
    "        # Number of clusters is set to cls\n",
    "        clusters = KMeans(n_clusters=cls, random_state=0).fit(X)\n",
    "        predG = dict()\n",
    "        for node in range(len(clusters.labels_)):\n",
    "            predG[node] = clusters.labels_[node]\n",
    "        \n",
    "        # compute the modularity score of the Kmeans clustering\n",
    "        modularity = comm.community_louvain.modularity(predG, G)\n",
    "        allmodularity.append(modularity)\n",
    "        print(\"Number of clusters: \", cls, \"  Modularity: \", modularity)\n",
    "        if modularity > bestModularity:\n",
    "            bestModularity = modularity\n",
    "            bestC = cls\n",
    "    plt.scatter(range(2, NOC), allmodularity)\n",
    "    plt.xlabel(\"Number of clusters\")\n",
    "    plt.ylabel(\"Modularity score\")\n",
    "    plt.show()\n",
    "    #print(\"Best Modularity:\",bestModularity, \"Clusters:\", bestC)\n",
    "\n",
    "    \n",
    "    \n",
    "def plot_embeddings(embeddings, label):\n",
    "\n",
    "    X, Y = read_node_label(label,skip_head=True)\n",
    "    emb_list = []\n",
    "    for k in X:\n",
    "        emb_list.append(embeddings[k])\n",
    "    emb_list = np.array(emb_list)\n",
    "\n",
    "    model = TSNE(n_components=2)\n",
    "    node_pos = model.fit_transform(emb_list)\n",
    "    color_idx = {}\n",
    "    \n",
    "\n",
    "    for i in range(len(X)):\n",
    "        color_idx.setdefault(Y[i][0], [])\n",
    "        color_idx[Y[i][0]].append(i)\n",
    "\n",
    "    for c, idx in color_idx.items():\n",
    "        plt.scatter(node_pos[idx, 0], node_pos[idx, 1], label=c)  # c=node_colors)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_f= {}\n",
    "clust_dic={}\n",
    "def clust_coeff(G):\n",
    "    global clust_f \n",
    "    global clust_dic\n",
    "    \n",
    "    clust_f= nx.clustering(G)\n",
    "    #print(clust_f)\n",
    "    for node,coeff in clust_f.items():\n",
    "        if coeff in clust_dic:\n",
    "            continue\n",
    "        else:\n",
    "            same_clust = {k for k,v in clust_f.items() if v == coeff}\n",
    "            clust_dic[coeff]=same_clust\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgree = {}\n",
    "same_degree_dic = {}\n",
    "def degree(G):\n",
    "    global dgree\n",
    "    global same_degree_dic\n",
    "    \n",
    "    dgree = dict(G.degree())\n",
    "    for node,deg in dgree.items():\n",
    "        if deg in same_degree_dic:\n",
    "            continue\n",
    "        else:\n",
    "            same_clust = {k for k,v in dgree.items() if v == deg}\n",
    "            same_degree_dic[deg]=same_clust\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = {}\n",
    "same_metric_dic = {}\n",
    "def metric_calc(G,met):\n",
    "    global metric \n",
    "    global same_metric_dic\n",
    "    \n",
    "  \n",
    "    if (met == \"bc\"):\n",
    "        metric = dict(nx.betweenness_centrality(G))\n",
    "        #b_cent_dic[centrality]=same_cent\n",
    "        print(\"\\nBetweeness Centrality\")\n",
    "    elif (met == \"cc\"):\n",
    "        metric=nx.closeness_centrality(G)\n",
    "        print(\"\\nCloseness Centrality\")\n",
    "    elif (met == \"ec\"):    \n",
    "        metric=nx.eigenvector_centrality(G)\n",
    "        print(\"\\nEigenvector Centrality\")\n",
    "    elif (met == \"dg\"):    \n",
    "        metric = dict(G.degree())\n",
    "        print(\"\\nDegree\")\n",
    "    elif (met == \"clust\"):    \n",
    "        metric = nx.clustering(G)\n",
    "        print(\"\\nClust\")\n",
    "    \n",
    "    for node,met in metric.items():\n",
    "        if met in same_metric_dic:\n",
    "            continue\n",
    "        else:\n",
    "            same_cent = {k for k,v in metric.items() if v == met}\n",
    "            same_metric_dic[met]=same_cent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_score = {}\n",
    "avg_score_dict = {}\n",
    "\n",
    "def metric_merging(G):\n",
    "    global avg_score \n",
    "    global avg_score_dict \n",
    "    \n",
    "    metric1 = nx.eigenvector_centrality(G)\n",
    "    #metric2 = dict(G.degree())\n",
    "    metric2 = nx.closeness_centrality(G)\n",
    "    \n",
    "    \n",
    "    for k,v in metric1.items():\n",
    "        if k in metric2:\n",
    "            avg_score[k] = (v+metric2[k])/2\n",
    "    \n",
    "    for node,score in avg_score.items():\n",
    "        if score in avg_score_dict:\n",
    "            continue\n",
    "        else:\n",
    "            same_score = {k for k,v in avg_score.items() if v == score}\n",
    "            avg_score_dict[score]=same_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(G, algorithm,num_walks):\n",
    "    #degree(G)\n",
    "    #clust_coeff(G)\n",
    "    metric_calc(G,algorithm)\n",
    "    #print(b_cent_dic)\n",
    "    metric2 = dict(G.degree())\n",
    "    #metric = nx.clustering(G)\n",
    "    #metric_merging(G)\n",
    "    #print(avg_score)\n",
    "    #print(avg_score_dict)\n",
    "    \n",
    "    if(algorithm == \"deepwalk\"):\n",
    "        model = DeepWalk(G, walk_length=10, num_walks=80, workers=1)\n",
    "    else:\n",
    "        model = Node2Vec(G, 10, num_walks, workers=1,p=0.8,q=1,metric1=metric, same_metric1_dic=same_metric_dic, metric2=metric2)\n",
    "        #model = Node2Vec(G, 10, num_walks, workers=1,p=0.25,q=2)\n",
    "        #model = Node2Vec(G, 10, 80, workers=1,p=0.25,q=1,dgree=dgree, same_degree_dic=same_degree_dic)\n",
    "   \n",
    "    model.train(embed_size=500, window_size=5, iter=3)\n",
    "    start = time.time()\n",
    "    embeddings = model.get_embeddings()\n",
    "    end = time.time()\n",
    "    print(\"Time elapsed for embedding\", end-start)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes:  2708\n",
      "Number of edges:  5429\n",
      "\n",
      "Eigenvector Centrality\n",
      "randomwalk took:  8.344650268554688e-06\n",
      "Preprocess transition probs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 59.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning embedding vectors...\n",
      "Learning embedding vectors done!\n",
      "Time elapsed for embedding 0.014950990676879883\n",
      "Time elapsed 3594.8330929279327\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "graphfile = 'data/Cora/cora.txt'\n",
    "labelfile = 'data/Cora/cora.nodes.labels'\n",
    "#graphfile = 'data/wiki/Wiki_edgelist.txt'\n",
    "#labelfile = 'data/wiki/wiki_labels.txt'\n",
    "#gaphfile = 'data/flight/brazil-airports.edgelist'\n",
    "#labelfile = 'data/flight/labels-brazil-airports.txt'\n",
    "#graphfile = 'data/git_web_ml/git_edges.txt'\n",
    "#labelfile = 'data/git_web_ml/git_features.txt'\n",
    "\n",
    "#G= nx.read_edgelist('data/git_web_ml/git_edges.txt', create_using = nx.DiGraph(), nodetype = None, data = [('weight', int)])\n",
    "#G= nx.read_edgelist('data/flight/brazil-airports.edgelist', create_using = nx.DiGraph(), nodetype = None, data = [('weight', int)])\n",
    "#G= nx.read_edgelist('data/wiki/Wiki_edgelist.txt', create_using = nx.DiGraph(), nodetype = None, data = [('weight', int)])\n",
    "G = nx.read_edgelist('data/Cora/cora.txt', create_using = nx.DiGraph(), nodetype = None, data = [('weight', int)])\n",
    "\n",
    "#G = nx.read_edgelist('test.txt', create_using = nx.DiGraph(), nodetype = None, data = [('weight', int)])\n",
    "#G = nx.read_edgelist('data/Cora/cora.txt',nodetype=None)\n",
    "G = G.to_directed()\n",
    "print(\"Number of nodes: \", G.number_of_nodes())\n",
    "print(\"Number of edges: \", G.number_of_edges())\n",
    "#dict(islice(degree.iteritems(), 0, 2))\n",
    "#print(dgree)\n",
    "#print(clust_f)#\n",
    "#Get embedding 128 dimension\n",
    "#for i in range(80,160,80):\n",
    "start = time.time()\n",
    "embeddings = get_embedding(G,\"ec\",80)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Time elapsed\", end-start)\n",
    "# plot the embedding \n",
    "#plot_embeddings(embeddings, labelfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "0.4188034188034188\n",
      "-------------------\n",
      "0.49548810500410173\n",
      "Training classifier using 20.00% nodes...\n",
      "-------------------\n",
      "0.5599630996309963\n",
      "-------------------\n",
      "0.5907172995780591\n",
      "Training classifier using 40.00% nodes...\n",
      "-------------------\n",
      "0.6150061500615006\n",
      "-------------------\n",
      "0.6233382570162481\n",
      "-------------------\n",
      "0.6439114391143912\n",
      "-------------------\n",
      "0.6560196560196561\n",
      "-------------------\n",
      "0.6789667896678967\n"
     ]
    }
   ],
   "source": [
    "# Evaluate node classification from embedding \n",
    "node_classification(embeddings, labelfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters:  2   Modularity:  0.18465502595299665\n",
      "Number of clusters:  3   Modularity:  0.42264536628911853\n",
      "Number of clusters:  4   Modularity:  0.4702575635155243\n",
      "Number of clusters:  5   Modularity:  0.5179273399373752\n",
      "Number of clusters:  6   Modularity:  0.5400351484372992\n",
      "Number of clusters:  7   Modularity:  0.568582349951991\n",
      "Number of clusters:  8   Modularity:  0.5797981597918878\n",
      "Number of clusters:  9   Modularity:  0.6081803954757399\n",
      "Number of clusters:  10   Modularity:  0.6127957413220901\n",
      "Number of clusters:  11   Modularity:  0.6257829011615059\n",
      "Number of clusters:  12   Modularity:  0.6092216312257863\n",
      "Number of clusters:  13   Modularity:  0.6119873351616044\n",
      "Number of clusters:  14   Modularity:  0.6127834644612158\n",
      "Number of clusters:  15   Modularity:  0.6196044632348221\n",
      "Number of clusters:  16   Modularity:  0.6294824721606026\n",
      "Number of clusters:  17   Modularity:  0.617954158775852\n",
      "Number of clusters:  18   Modularity:  0.6221789963443674\n",
      "Number of clusters:  19   Modularity:  0.6314784671757663\n",
      "Number of clusters:  20   Modularity:  0.6358377399605789\n",
      "Number of clusters:  21   Modularity:  0.6275106539460201\n",
      "Number of clusters:  22   Modularity:  0.6253894313602145\n",
      "Number of clusters:  23   Modularity:  0.6201276477635078\n",
      "Number of clusters:  24   Modularity:  0.6420114573983595\n",
      "Number of clusters:  25   Modularity:  0.6361784407984641\n",
      "Number of clusters:  26   Modularity:  0.634440870114976\n",
      "Number of clusters:  27   Modularity:  0.6527112262631201\n",
      "Number of clusters:  28   Modularity:  0.652968053166992\n",
      "Number of clusters:  29   Modularity:  0.647572013840258\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.io import mmread,mminfo\n",
    "from community import community_louvain\n",
    "filename = \"data/Cora/cora.mtx\"\n",
    "#filename = \"data/wiki/Wiki_edgelist.mtx\"\n",
    "#filename = \"data/flight/brazil-airports.mtx\"\n",
    "g = mmread(filename)\n",
    "nxG = nx.Graph(g)\n",
    "\n",
    "cluster_eval(nxG, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link predictions: 0.05 :Accuracy: 0.5559876358560175 F1-macro: 0.5467204218321973 F1-micro: 0.5559876358560175\n",
      "Link predictions: 0.1 :Accuracy: 0.5469950531522998 F1-macro: 0.5455432675778494 F1-micro: 0.5469950531522998\n",
      "Link predictions: 0.2 :Accuracy: 0.5438721136767318 F1-macro: 0.5437103669343966 F1-micro: 0.5438721136767318\n",
      "Link predictions: 0.3 :Accuracy: 0.5466847090663058 F1-macro: 0.5460047316075847 F1-micro: 0.5466847090663058\n",
      "Link predictions: 0.4 :Accuracy: 0.5560467319229555 F1-macro: 0.5553760649281659 F1-micro: 0.5560467319229555\n",
      "Link predictions: 0.5 :Accuracy: 0.5479348237968927 F1-macro: 0.5476255682830524 F1-micro: 0.5479348237968927\n",
      "Link predictions: 0.6 :Accuracy: 0.5382429552450865 F1-macro: 0.5381994261119083 F1-micro: 0.5382429552450865\n",
      "Link predictions: 0.7 :Accuracy: 0.5446795074202716 F1-macro: 0.5445519533104355 F1-micro: 0.5446795074202716\n",
      "Link predictions: 0.8 :Accuracy: 0.5705492424242424 F1-macro: 0.5703711512000709 F1-micro: 0.5705492424242424\n"
     ]
    }
   ],
   "source": [
    "makeLinkPredictionData(nxG, embeddings) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
